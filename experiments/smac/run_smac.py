import numpy as np
import keras
import json
import sys
import os

from os.path import dirname, abspath, realpath, join as path_join

from smac.scenario.scenario import Scenario
from smac.facade.smac_facade import SMAC

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D

from sklearn.model_selection import train_test_split

PARENT_DIRECTORY = path_join(dirname(realpath(__file__)), "..", "..")
sys.path.insert(0, PARENT_DIRECTORY)

from autoda.data_augmentation import ImageAugmentation


run_id = int(sys.argv[1])
path = path_join(abspath("."), "Workspace/MastersThesis/AutoDA/experiments/smac/results/mnist")


def cnn_from_config(config):
    """ Trains LeNet on augmented MNIST data with augmentation parameters from
        a given configuration space

    Parameters
    ----------
    config: Configuration(ConfigSpace.ConfigurationSpace.Configuration)
         Configuration space, contains parameters to be optimized

    Returns:
    -------
    validation_accuracy: numpy.ndarray
    Accuracy of given configuration on MNIST Data

    """

    batch_size = 128
    num_classes = 10
    epochs = 12

    # input image dimensions
    img_rows, img_cols = 28, 28

    # The data, shuffled and split between train and test sets:
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)

    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')

    x_train /= 255
    x_test /= 255

    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train)
    print('x_train shape:', x_train.shape)

    print(x_train.shape[0], 'train samples')
    print(x_valid.shape[0], 'validation samples')
    print(x_test.shape[0], 'test samples')

    # Convert class vectors to binary class matrices.
    y_train = keras.utils.to_categorical(y_train, num_classes)
    y_valid = keras.utils.to_categorical(y_valid, num_classes)
    y_test = keras.utils.to_categorical(y_test, num_classes)

    # LeNet
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3),
                     activation='relu',
                     input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    # Let's train the model using ADAM

    model.compile(loss=keras.losses.categorical_crossentropy,
                  optimizer=keras.optimizers.Adam(),
                  metrics=['accuracy'])

    print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:

    imagegen = ImageAugmentation(config)

    # Fit the model on the batches generated by datagen.flow().
    model.fit_generator(imagegen.apply_transform(x_train, y_train,
                                                 batch_size=batch_size),
                        steps_per_epoch=x_train.shape[0] // batch_size,
                        epochs=epochs,
                        validation_data=(x_valid, y_valid)
                        )

    # Evaluate model with test data set and share sample prediction results
    score = model.evaluate(x_valid, y_valid, verbose=0)
    print("score", score)
    # return validation error
    return 1 - score[1]


# Optimize with SMAC

config_space = ImageAugmentation.get_config_space()
# Scenario object
scenario = Scenario({"run_obj": "quality",   # we optimize quality (alternatively runtime)
                     "runcount-limit": 100,  # maximum function evaluations
                     "cs": config_space,     # configuration space
                     "deterministic": "true"
                     })

# Example call of the function
# It returns: Status, Cost, Runtime, Additional Infos
default_value = config_space.get_default_configuration()
print("Default Value: {}".format(default_value))

# Optimize, using a SMAC-object
print("Optimizing! Depending on your machine, this might take a few minutes.")
smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),
            tae_runner=cnn_from_config)

incumbent = smac.optimize()

incumbent_value = cnn_from_config(incumbent)

print("Optimized Value: {}".format(incumbent_value))

with open(os.path.join(path, "smac_optimized_%d.json" % run_id), "w") as fh:
    json.dump(incumbent_value, fh)

